{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Hack: Classifying mergers in Eagle simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are eagle simulations?\n",
    "why eagle? \n",
    "long term goal \n",
    "short term goal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying mergers by their Size and Mass Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/EM.png\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/classification.png\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the data - https://drive.google.com/drive/folders/1AMv2tWMj11mR5O2KA86Ab4z9XQZRBD5r?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(path, N, parameter): \n",
    "    ''''\n",
    "    Retrieving the galaxy merger images and their corresponding labels of size and mass ratio\n",
    "    \n",
    "    i/p params:\n",
    "    \n",
    "    path - path of the images and labels\n",
    "    N - number of images we want in the training set\n",
    "    parameter - Mass/Size ratio \n",
    "    \n",
    "    o/p params:\n",
    "    \n",
    "    X - an np 3D array of randomly picked 'N' galaxy merger images. The 3D is to comply with the dimensional \n",
    "    requirement of the neural network. Here, the images are black and white so all 3 dimensions are the same. \n",
    "    Y - labels \n",
    "    \n",
    "    ''''\n",
    "    \n",
    "    X =[]\n",
    "    Y = np.array([])\n",
    "    redshift=[]\n",
    "    merger=[]\n",
    "\n",
    "    for path, subdirs, image_names in os.walk(path+ '/eagle_images'):\n",
    "        image_names=np.array(image_names)\n",
    "        index_store= np.where(image_names=='.DS_Store')[0]\n",
    "        image_names=np.delete(image_names,index_store)\n",
    "        ind=np.random.choice(np.arange(len(image_names)),N)   #indices of N randomly picked images \n",
    "        picked_image_names= image_names[ind]                  #images pertaining to these indices \n",
    "        \n",
    "        for i, name in enumerate(picked_image_names):\n",
    "            if name.endswith('.jpg'): \n",
    "                img_path = os.path.join(path,name)\n",
    "                img_pixels = np.array(Image.open(img_path).getdata())\n",
    "                X.append(img_pixels)\n",
    "                redshift.append(int(name.split('_')[1]))\n",
    "                merger.append(int(name.split('_')[2]))\n",
    "                f= h5py.File(path+'/mergers_identified/mergers_'+str(int(redshift[-1]))+'.hdf5', 'r')\n",
    "                Y=list(np.append(Y,f.get(parameter).value[int(merger[-1])]))\n",
    "    \n",
    "    X=np.array(X)\n",
    "    X=X.reshape((len(Y),224,224,3))\n",
    "    Y=np.array(Y)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data(path, 100, parameter= 'Size Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)#, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(XX_train))\n",
    "print(len(XX_test))\n",
    "print(len(Y_train))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train=np.array(XX_train)\n",
    "Y_train=np.array(Y_train)\n",
    "XX_test=np.array(XX_test)\n",
    "Y_test=np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.keras import layers \n",
    "from tensorflow.python.keras.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from keras.metrics import top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yround_train= np.array([])\n",
    "Yround_test= np.array([]) \n",
    "\n",
    "cl=[0,0.25,0.5,0.75,1.0,1.25]\n",
    "\n",
    "Y_train_ohe = np.zeros((len(Y_train), 5), dtype=np.int)\n",
    "Y_test_ohe= np.zeros((len(Y_test), 5), dtype=np.int)\n",
    "\n",
    "for i in np.arange(len(Y_train)):\n",
    "    for j in np.arange(1,len(cl)):\n",
    "        if Y_train[i]> cl[j-1] and  Y_train[i]< cl[j]: \n",
    "            Yround_train=np.append(Yround_train,cl[j])\n",
    "            Y_train_ohe[i, j-1] = 1\n",
    "\n",
    "for i in np.arange(len(Y_test)):\n",
    "    for j in np.arange(1,len(cl)):\n",
    "        if Y_test[i]> cl[j-1] and  Y_test[i]< cl[j]: \n",
    "            Yround_test=np.append(Yround_test,cl[j])\n",
    "            Y_test_ohe[i, j-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yround_train,Yround_test, Y_train_ohe, Y_test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers,models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist(): \n",
    "    \n",
    "    def mnistmodel(inputs): \n",
    "\n",
    "        \"\"\"\n",
    "        Creates and returns neural net model\n",
    "        \"\"\"\n",
    "\n",
    "        x = layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                          activation='relu',\n",
    "                          padding='valid',\n",
    "                          data_format=backend.image_data_format(),\n",
    "                          input_shape=(224,224,3))(inputs)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Conv2D(32, kernel_size=(3, 3), activation='relu',padding='valid')(x)\n",
    "        x = layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2))(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        #x = layers.Dense(self.nclasses, activation='sigmoid')(x)\n",
    "        x = layers.Dense(5, activation='softmax')(x)\n",
    "        return x\n",
    "\n",
    "    model_input = layers.Input(shape=(224,224,3))\n",
    "    model_output = mnistmodel(model_input)\n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    return model\n",
    "\n",
    "model= mnist()\n",
    "BS=2\n",
    "\n",
    "sgd=optimizers.SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "model.compile(loss=categorical_crossentropy,optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "callbacks=[TensorBoard(log_dir='/home/vasist/Tensorboard/TB_resnet50_'+str(100), batch_size=BS), ModelCheckpoint('/home/vasist/Model/M_resnet50_'+str(100),monitor='val_acc',verbose=1,period=1)]  #-{val_accuracy:.2f}\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(horizontal_flip=True)#, rotation_range=20, zoom_range=0.15,\n",
    "#width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, fill_mode=\"nearest\")\n",
    "\n",
    "# train the network\n",
    "# validation_steps= int((len(XX_test)+BS-1)/BS)-1\n",
    "# train_steps=int((len(XX_train)+BS-1)/BS)-1\n",
    "\n",
    "validation_steps= len(XX_test)//BS\n",
    "train_steps=len(XX_train)//BS\n",
    "print(validation_steps,train_steps)\n",
    "\n",
    "H = model.fit_generator(aug.flow(XX_train, Y_train_ohe, batch_size=BS),\n",
    "validation_data=aug.flow(XX_test, Y_test_ohe), steps_per_epoch=train_steps,\n",
    "epochs=100,callbacks=callbacks,validation_steps=validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in aug.flow(XX_train, Y_train_ohe,batch_size=3): \n",
    "#     fig=plt.figure(figsize=(15,7))\n",
    "#     for i in range(0, len(x)):\n",
    "#         plt.subplot(330 + 1 + i)\n",
    "# #         if x[i] : \n",
    "#         Tx=x[i].T[0]\n",
    "#         print(cl[np.nonzero(y[i])[0][0]+1])\n",
    "#         plt.imshow(Tx)\n",
    "#     plt.show()\n",
    "#     if len(x)<3: \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
